{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse\n",
    "import datetime\n",
    "import sys\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "import models\n",
    "#import objectives\n",
    "import objectives_dev as objectives\n",
    "from utils import Logger, Timer, save_model, save_vars, unpack_data\n",
    "\n",
    "from utils import log_mean_exp, is_multidata, kl_divergence, get_mean\n",
    "\n",
    "from datasets_dev import ATAC_Dataset, RNA_Dataset\n",
    "\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import prod, sqrt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from utils import Constants\n",
    "from vis import plot_embeddings, plot_kls_df\n",
    "\n",
    "#args\n",
    "experiment = 'rna_atac'\n",
    "model = 'rna_atac_dev' \n",
    "obj = 'dreg'\n",
    "K = 20\n",
    "looser = True\n",
    "llik_scaling = 0\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "latent_dim = 20\n",
    "num_hidden_layers = 1\n",
    "learn_prior = False\n",
    "logp = False\n",
    "print_freq = 0\n",
    "no_analytics = False\n",
    "seed = 1\n",
    "\n",
    "class params():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 experiment,\n",
    "                 model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed):\n",
    "        \n",
    "        self.experiment = experiment\n",
    "        self.model = model\n",
    "        self.obj = obj\n",
    "        self.K = K\n",
    "        self.looser = looser\n",
    "        self.llik_scaling = llik_scaling\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.learn_prior = learn_prior\n",
    "        self.logp = logp\n",
    "        self.print_freq = print_freq\n",
    "        self.no_analytics = no_analytics\n",
    "        self.seed = seed\n",
    "        \n",
    "args = params(experiment,\n",
    "                model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# load model\n",
    "modelC = getattr(models, 'VAE_{}'.format(args.model))\n",
    "model = modelC(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model rna-atac from ../experiments/rna_atac\n"
     ]
    }
   ],
   "source": [
    "#Select pretrained model\n",
    "pretrained_path = '../experiments/' + args.experiment\n",
    "\n",
    "print('Loading model {} from {}'.format(model.modelName, pretrained_path))\n",
    "\n",
    "model.load_state_dict(torch.load(pretrained_path + '/model.rar'))\n",
    "model._pz_params = model._pz_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up run path\n",
    "runId = datetime.datetime.now().isoformat()\n",
    "experiment_dir = Path('../experiments/' + args.experiment)\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "runPath = mkdtemp(prefix=runId, dir=str(experiment_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  data ...\n",
      "Original data contains 5081 cells x 19322 peaks\n",
      "Finished loading takes 0.05 min\n",
      "Loading  data ...\n",
      "Original data contains 5081 cells x 229429 peaks\n",
      "Finished loading takes 0.33 min\n"
     ]
    }
   ],
   "source": [
    "train, test = model.getDataLoaders(batch_size=args.batch_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-611bdffa8343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m#data = unpack_data(d,device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#data = d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-611bdffa8343>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m#data = unpack_data(d,device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#data = d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(train):\n",
    "    if i==0:\n",
    "        #data = unpack_data(d,device=device)\n",
    "        #data = d\n",
    "        data = [d.to(device) for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([10, 19322])\n",
      "torch.Size([10, 43703])\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5081\n",
      "2\n",
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(len(ds))\n",
    "print(len(ds[0]))\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n"
     ]
    }
   ],
   "source": [
    "print(len([*train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.no_grad()\n",
    "\n",
    "_, px_zs, _ = model.forward(data)\n",
    "# cross-modal matrix of reconstructions\n",
    "recons_mat = [[get_mean(px_z) for px_z in r] for r in px_zs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "torch.Size([1, 10, 19322])\n",
      "torch.Size([1, 10, 43703])\n"
     ]
    }
   ],
   "source": [
    "#print(recons)\n",
    "print(len(recons_mat))\n",
    "print(len(recons_mat[0]))\n",
    "print(len(recons_mat[1]))\n",
    "print(recons_mat[0][0].shape)\n",
    "print(recons_mat[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, recons_list in enumerate(recons_mat):\n",
    "            for o, recon in enumerate(recons_list):\n",
    "                _data = data[r].cpu()\n",
    "                recon = recon.squeeze(0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 43703])\n",
      "torch.Size([10, 43703])\n"
     ]
    }
   ],
   "source": [
    "print(_data.shape)\n",
    "print(recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model.getDataLoaders(batch_size=5081,device=device) #姑息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in test:\n",
    "    x = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reconstruct(x,runPath,epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoadersMNIST(batch_size, shuffle=True, device=\"cuda\"):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if device == \"cuda\" else {}\n",
    "    tx = transforms.ToTensor()\n",
    "    train = DataLoader(datasets.MNIST('../data', train=True, download=True, transform=tx),\n",
    "                        batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "    test = DataLoader(datasets.MNIST('../data', train=False, download=True, transform=tx),\n",
    "                        batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoadersRNA(batch_size, shuffle=True, device=\"cuda\"):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if device == \"cuda\" else {}\n",
    "\n",
    "    #SingleCellDatasetを移植\n",
    "    path = '../data/SNARE-seq/RNA-seq' #後でarg指定できるようにする\n",
    "    transpose = False \n",
    "        \n",
    "    dataset = RNA_Dataset(path,transpose=transpose)\n",
    "        \n",
    "    train = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n",
    "    test = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False, **kwargs)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoadersATAC(batch_size, shuffle=True, device=\"cuda\"):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if device == \"cuda\" else {}\n",
    "        \n",
    "    #SingleCellDatasetを移植\n",
    "    path = '../data/SNARE-seq/ATAC-seq'\n",
    "    low = 0.01\n",
    "    high = 0.9\n",
    "    min_peaks = 100\n",
    "    transpose = False \n",
    "    dataset = ATAC_Dataset(path, low=low, high=high, min_peaks=min_peaks,transpose=transpose)\n",
    "        \n",
    "    dataset.create_binary()\n",
    "        \n",
    "    train = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n",
    "    test = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False, **kwargs)\n",
    "        \n",
    "    return train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoadersRNA_ATAC(self, batch_size, shuffle=True, device='cuda'):\n",
    "\n",
    "        # load base datasets\n",
    "        t1, s1 = self.vaes[0].getDataLoaders(batch_size, shuffle, device)\n",
    "        t2, s2 = self.vaes[1].getDataLoaders(batch_size, shuffle, device)\n",
    "\n",
    "        train_rna_atac = TensorDataset([\n",
    "            ResampleDataset(t1.dataset),\n",
    "            ResampleDataset(t2.dataset)\n",
    "        ])\n",
    "        test_rna_atac = TensorDataset([\n",
    "            ResampleDataset(s1.dataset),\n",
    "            ResampleDataset(s2.dataset)\n",
    "        ])\n",
    "\n",
    "        kwargs = {'num_workers': 2, 'pin_memory': True} if device == 'cuda' else {}\n",
    "\n",
    "        train = DataLoader(train_rna_atac, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "        test = DataLoader(test_rna_atac, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "        return train, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_multimodal",
   "language": "python",
   "name": "venv_multimodal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
