{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse\n",
    "import datetime\n",
    "import sys\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models\n",
    "import objectives_dev as objectives\n",
    "#from utils import Logger, Timer, save_model, save_vars, unpack_data\n",
    "from utils_dev import Logger, Timer, save_model, save_vars, unpack_data, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "experiment = 'test'\n",
    "model = 'rna_atac_dev' #VAE試しに使う\n",
    "obj = 'elbo'\n",
    "K = 10\n",
    "looser = False\n",
    "llik_scaling = 0\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "latent_dim = 8\n",
    "num_hidden_layers = 2\n",
    "hidden_dim =128\n",
    "learn_prior = False\n",
    "logp = False\n",
    "print_freq = 0\n",
    "no_analytics = False\n",
    "seed = 1\n",
    "dataSize = []\n",
    "\n",
    "class params():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 experiment,\n",
    "                 model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 hidden_dim,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed,\n",
    "                dataSize):\n",
    "        \n",
    "        self.experiment = experiment\n",
    "        self.model = model\n",
    "        self.obj = obj\n",
    "        self.K = K\n",
    "        self.looser = looser\n",
    "        self.llik_scaling = llik_scaling\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.learn_prior = learn_prior\n",
    "        self.logp = logp\n",
    "        self.print_freq = print_freq\n",
    "        self.no_analytics = no_analytics\n",
    "        self.seed = seed\n",
    "        self.dataSize = dataSize\n",
    "        \n",
    "args = params(experiment,\n",
    "                model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 hidden_dim,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed,\n",
    "                 dataSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "modelC = getattr(models, 'VAE_{}'.format(args.model))\n",
    "model = modelC(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA_ATAC(\n",
      "  (vaes): ModuleList(\n",
      "    (0): RNA(\n",
      "      (enc): Enc(\n",
      "        (enc): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): Linear(in_features=23758, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (fc21): Linear(in_features=128, out_features=8, bias=True)\n",
      "        (fc22): Linear(in_features=128, out_features=8, bias=True)\n",
      "      )\n",
      "      (dec): Dec(\n",
      "        (dec): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (fc31): Linear(in_features=128, out_features=23758, bias=True)\n",
      "        (fc32): Linear(in_features=128, out_features=23758, bias=True)\n",
      "      )\n",
      "      (_pz_params): ParameterList(\n",
      "          (0): Parameter containing: [torch.FloatTensor of size 1x8]\n",
      "          (1): Parameter containing: [torch.FloatTensor of size 1x8]\n",
      "      )\n",
      "    )\n",
      "    (1): ATAC(\n",
      "      (enc): Enc(\n",
      "        (enc): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): Linear(in_features=26076, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (fc21): Linear(in_features=128, out_features=8, bias=True)\n",
      "        (fc22): Linear(in_features=128, out_features=8, bias=True)\n",
      "      )\n",
      "      (dec): Dec(\n",
      "        (dec): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (fc3): Linear(in_features=128, out_features=26076, bias=True)\n",
      "      )\n",
      "      (_pz_params): ParameterList(\n",
      "          (0): Parameter containing: [torch.FloatTensor of size 1x8]\n",
      "          (1): Parameter containing: [torch.FloatTensor of size 1x8]\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_pz_params): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 1x8]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 1x8]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/junk/2020-04-18T14:25:44.897101jxrkmmr3\n"
     ]
    }
   ],
   "source": [
    "# set up run path\n",
    "runId = datetime.datetime.now().isoformat()\n",
    "experiment_dir = Path('../experiments/' + args.experiment)\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "runPath = mkdtemp(prefix=runId, dir=str(experiment_dir))\n",
    "print(runPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preparation for training\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                       lr=1e-4, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  data ...\n",
      "Original data contains 10309 cells x 33160 peaks\n",
      "Finished loading takes 1.21 min\n",
      "Loading  data ...\n",
      "Original data contains 10309 cells x 244544 peaks\n",
      "Finished loading takes 0.84 min\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = model.getDataLoaders(args.batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, vae in enumerate(model.vaes):\n",
    "    args.dataSize.append(torch.Size([1, len(train_loader.dataset[0][m])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23758"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function m_elbo_warmup at 0x130929bf8>\n"
     ]
    }
   ],
   "source": [
    "#objective = getattr(objectives,\n",
    "#                    ('m_' if hasattr(model, 'vaes') else '')\n",
    "#                    + args.obj\n",
    "#                    + ('_looser' if (args.looser and args.obj != 'elbo') else ''))\n",
    "objective = getattr(objectives, 'm_elbo_warmup') #test warmup\n",
    "\n",
    "t_objective = getattr(objectives, ('m_' if hasattr(model, 'vaes') else '') + 'iwae')\n",
    "\n",
    "print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, agg, W=30):\n",
    "    model.train()\n",
    "    b_loss = 0\n",
    "    beta = (epoch - 1) / W  if epoch <= W else 1\n",
    "    for i, dataT in enumerate(train_loader):\n",
    "        \n",
    "        #data = unpack_data(dataT, device=device)\n",
    "        data = dataT #mmvae_rna_atac\n",
    "        optimizer.zero_grad()\n",
    "        #loss = -objective(model, data, K=args.K)\n",
    "        loss = -objective(model, data, beta, K=args.K)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        b_loss += loss.item()\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, agg, W=30):\n",
    "    model.eval()\n",
    "    b_loss = 0\n",
    "    beta = (epoch - 1) / W  if epoch <= W else 1\n",
    "    with torch.no_grad():\n",
    "        for i, dataT in enumerate(val_loader):\n",
    "            #data = unpack_data(dataT, device=device)\n",
    "            data = dataT #mmvae_rna_atac\n",
    "            #loss = -t_objective(model, data, K=args.K)\n",
    "            #loss = -objective(model, data, K=args.K)\n",
    "            loss = -objective(model, data, beta, K=args.K)\n",
    "            b_loss += loss.item()\n",
    "    agg['val_loss'].append(b_loss / len(val_loader.dataset))\n",
    "    print('====>             Validation loss: {:.4f}'.format(agg['val_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, agg, W=30):\n",
    "    model.eval()\n",
    "    b_loss = 0\n",
    "    beta = (epoch - 1) / W  if epoch <= W else 1\n",
    "    with torch.no_grad():\n",
    "        for i, dataT in enumerate(test_loader):\n",
    "            \n",
    "            #data = unpack_data(dataT, device=device)\n",
    "            data = dataT #mmvae_rna_atac\n",
    "            \n",
    "            #loss = -t_objective(model, data, K=args.K)\n",
    "            #loss = -objective(model, data, K=args.K)\n",
    "            loss = -objective(model, data, beta, K=args.K)\n",
    "            b_loss += loss.item()\n",
    "            #if i == 0:\n",
    "            #    model.reconstruct(data, runPath, epoch)\n",
    "            #model.reconstruct(data, runPath, epoch, sampling=False, N=1)\n",
    "            #    if not args.no_analytics:\n",
    "           # model.analyse(data, runPath, epoch)\n",
    "    agg['test_loss'].append(b_loss / len(test_loader.dataset))\n",
    "    print('====>             Test loss: {:.4f}'.format(agg['test_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_log_marginal(K):\n",
    "    \"\"\"Compute an IWAE estimate of the log-marginal likelihood of test data.\"\"\"\n",
    "    model.eval()\n",
    "    marginal_loglik = 0\n",
    "    with torch.no_grad():\n",
    "        for dataT in test_loader:\n",
    "            data = unpack_data(dataT, device=device)\n",
    "            marginal_loglik += -t_objective(model, data, K).item()\n",
    "\n",
    "    marginal_loglik /= len(test_loader.dataset)\n",
    "    print('Marginal Log Likelihood (IWAE, K = {}): {:.4f}'.format(K, marginal_loglik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 001 Train loss: 66731.9997\n",
      "====>             Validation loss: 55159.3871\n",
      "Validation loss decreased (inf --> 55159.387136).  Saving model ...\n",
      "====>             Test loss: 48476.2845\n",
      "====> Epoch: 002 Train loss: 48256.8420\n",
      "====>             Validation loss: 16817.6148\n",
      "Validation loss decreased (55159.387136 --> 16817.614819).  Saving model ...\n",
      "====>             Test loss: 16762.3241\n",
      "====> Epoch: 003 Train loss: 13528.2078\n",
      "====> [MM-VAE] Time: 528.746s or 00:08:48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-229e5fd94150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# early_stopping needs the validation loss to check if it has decresed,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# and if it has, it will make a checkpoint of the current model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mearly_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f0d4d6b0ccb3>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(epoch, agg, W)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m#loss = -t_objective(model, data, K=args.K)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#loss = -objective(model, data, K=args.K)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mb_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/multimodal/src/objectives_dev.py\u001b[0m in \u001b[0;36mm_elbo_warmup\u001b[0;34m(model, x, beta, K)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mklds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx_zs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mlpx_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx_zs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpx_zs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mlpx_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlpx_z\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllik_scaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/multimodal/venv_multimodal/lib/python3.7/site-packages/torch-1.3.1-py3.7-macosx-10.9-x86_64.egg/torch/distributions/negative_binomial.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         log_unnormalized_prob = (self.total_count * F.logsigmoid(-self.logits) +\n\u001b[0m\u001b[1;32m     93\u001b[0m                                  value * F.logsigmoid(self.logits))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sys.stdout = Logger('{}/run.log'.format(runPath))\n",
    "#print('Expt:', runPath)\n",
    "#print('RunID:', runId)\n",
    "            \n",
    "with Timer('MM-VAE') as t:\n",
    "        agg = defaultdict(list)\n",
    "        # initialize the early_stopping object\n",
    "        early_stopping = EarlyStopping(patience=7, verbose=True) \n",
    "        \n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            train(epoch, agg)\n",
    "            #save_model(model, runPath + '/model.rar')\n",
    "            save_vars(agg, runPath + '/losses.rar')\n",
    "            \n",
    "            # early_stopping needs the validation loss to check if it has decresed, \n",
    "            # and if it has, it will make a checkpoint of the current model\n",
    "            validate(epoch, agg)\n",
    "            early_stopping(agg['val_loss'][-1], model, runPath)\n",
    "            if early_stopping.early_stop:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "            \n",
    "            test(epoch, agg)\n",
    "            #model.generate(runPath, epoch)\n",
    "       # if args.logp:  # compute as tight a marginal likelihood as possible\n",
    "           # estimate_log_marginal(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_t, recon_v, recon_s = model.getDataLoaders(batch_size=1024,device=device) #姑息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(recon_s): #データ取得\n",
    "    if i == 0:\n",
    "        data = d #get first mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reconstruct(data, runPath, epoch=1, sampling=True, N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.analyse(data, runPath, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE\n",
    "for i, d in enumerate(recon_t):\n",
    "    if i == 0:\n",
    "        data = d\n",
    "    else:\n",
    "        data = torch.cat([data, d], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMVAE\n",
    "for i, d in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        data0 = d[0]\n",
    "        data1 = d[1]\n",
    "    else:\n",
    "        data0 = torch.cat([data0, d[0]], dim=0)\n",
    "        data1 = torch.cat([data1, d[1]], dim=0)\n",
    "data = [data0, data1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8350, 23758])\n",
      "torch.Size([8350, 220258])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].shape)\n",
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#full_t, full_s = model.getDataLoaders(batch_size=,device=device) #姑息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,d in enumerate(full_s): #full データ取得\n",
    "#    if i == 0:\n",
    "#        full_data = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize_latent(data, runPath, epoch=1, tsne=True, sampling = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 2d latent\n",
    "lats = model.latents(data, sampling = False)\n",
    "if len(lats) == 2:\n",
    "    lat_rna = lats[0]\n",
    "    lat_atac = lats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(lats) == 2:\n",
    "    plt.figure()\n",
    "    plt.scatter(lat_rna[:,0],lat_rna[:,1],s=0.5)\n",
    "    plt.savefig('{}/lat_rna.png'.format(runPath ), dpi=1000)\n",
    "    plt.close('all')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(lat_atac[:,0],lat_atac[:,1],s=0.5)\n",
    "    plt.savefig('{}/lat_atac.png'.format(runPath ), dpi=1000)\n",
    "    plt.close('all')\n",
    "\n",
    "else: \n",
    "    plt.figure()\n",
    "    plt.scatter(lats[:,0],lats[:,1],s=0.5)\n",
    "    plt.savefig('{}/lat.png'.format(runPath ), dpi=1000)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lats = sum(lats)/len(lats)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mean_lats[:,0],mean_lats[:,1],s=0.5)\n",
    "plt.savefig('{}/lat_mean.png'.format(runPath ), dpi=1000)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(train_loader):\n",
    "    if i==0:\n",
    "        atac = d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 56340])\n"
     ]
    }
   ],
   "source": [
    "print(atac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  6,  4,  ..., 19,  8,  6])\n",
      "tensor(242201)\n",
      "56340\n"
     ]
    }
   ],
   "source": [
    "print(sum(atac==1))\n",
    "print(sum(sum(atac==1)))\n",
    "print(len(sum(atac==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7211520"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*56340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664147086883209"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6969319/7211520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03358529131167909"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "242201/7211520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_multimodal",
   "language": "python",
   "name": "venv_multimodal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
