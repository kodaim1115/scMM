{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse\n",
    "import datetime\n",
    "import sys\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchnet.dataset import TensorDataset, ResampleDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import models\n",
    "import objectives_dev as objectives\n",
    "#from utils import Logger, Timer, save_model, save_vars, unpack_data\n",
    "from utils_dev import Logger, Timer, save_model, save_vars, unpack_data, EarlyStopping, vade_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "experiment = 'test'\n",
    "model = 'rna_atac_dev' #VAE試しに使う\n",
    "obj = 'elbo'\n",
    "K = 1\n",
    "looser = False\n",
    "llik_scaling = 0\n",
    "batch_size = 1024\n",
    "epochs = 100\n",
    "n_centroids = 10\n",
    "latent_dim = 20\n",
    "num_hidden_layers = 1\n",
    "hidden_dim = [128, 128]\n",
    "learn_prior = False\n",
    "logp = False\n",
    "print_freq = 0\n",
    "no_analytics = False\n",
    "seed = 1\n",
    "dataSize = []\n",
    "r_dim = a_dim = []\n",
    "\n",
    "class params():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 experiment,\n",
    "                 model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 n_centroids,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 hidden_dim,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed,\n",
    "                dataSize,\n",
    "                r_dim,\n",
    "                a_dim):\n",
    "        \n",
    "        self.experiment = experiment\n",
    "        self.model = model\n",
    "        self.obj = obj\n",
    "        self.K = K\n",
    "        self.looser = looser\n",
    "        self.llik_scaling = llik_scaling\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.n_centroids = n_centroids\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.learn_prior = learn_prior\n",
    "        self.logp = logp\n",
    "        self.print_freq = print_freq\n",
    "        self.no_analytics = no_analytics\n",
    "        self.seed = seed\n",
    "        self.dataSize = dataSize\n",
    "        self.r_dim = r_dim\n",
    "        self.a_dim = a_dim\n",
    "        \n",
    "args = params(experiment,\n",
    "                model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 n_centroids,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 hidden_dim,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed,\n",
    "                 dataSize,\n",
    "                 r_dim,\n",
    "                 a_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up run path\n",
    "#runId = datetime.datetime.now().isoformat()\n",
    "runId ='test'\n",
    "experiment_dir = Path('../experiments/' + args.experiment)\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "runPath = mkdtemp(prefix=runId, dir=str(experiment_dir))\n",
    "print(runPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_loader = model.getDataLoaders(batch_size=args.batch_size, device=device) #for train only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/Paired-seq/combined/'\n",
    "r_dataset = torch.load(dataset_path + 'r_dataset.rar')\n",
    "a_dataset = torch.load(dataset_path + 'a_dataset.rar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5000\n",
    "#num = 25845\n",
    "r_dataset = Subset(r_dataset, list(range(num)))\n",
    "a_dataset = Subset(a_dataset, list(range(num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= TensorDataset([\n",
    "    #ResampleDataset(r_dataset),\n",
    "    #ResampleDataset(a_dataset)\n",
    "    r_dataset,\n",
    "    a_dataset\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.r_dim = r_dataset.data.shape[1]\n",
    "#args.a_dim = a_dataset.data.shape[1]\n",
    "args.r_dim = r_dataset.dataset.shape[1]\n",
    "args.a_dim = a_dataset.dataset.shape[1]\n",
    "r_dataset = a_dataset = train_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "modelC = getattr(models, 'VAE_{}'.format(args.model))\n",
    "model = modelC(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation for training\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                       lr=1e-4, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_objective  = getattr(objectives, 'elbo_ae') \n",
    "pre_objective  = getattr(objectives, 'm_elbo_naive_ae') \n",
    "#pretrained_path = '../data/Paired-seq/combined/RNA-seq/'\n",
    "pretrained_path = '../data/Paired-seq/combined/subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(epoch, agg):\n",
    "    model.train()\n",
    "    b_loss = 0\n",
    "    for i, dataT in enumerate(train_loader):\n",
    "        \n",
    "        #data = unpack_data(dataT, device=device) #unimodal\n",
    "        data = dataT #multimodal\n",
    "        optimizer.zero_grad()\n",
    "        #loss = -objective(model, data, K=args.K)\n",
    "        loss = -pre_objective(model, data, K=args.K)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        b_loss += loss.item()\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('MM-VAE') as t:\n",
    "        agg = defaultdict(list)\n",
    "        pretrain_epoch = 5\n",
    "        for epoch in range(1, pretrain_epoch + 1):\n",
    "            pretrain(epoch, agg)\n",
    "            save_model(model, pretrained_path + '/model.rar')\n",
    "            save_vars(agg, pretrained_path + '/losses.rar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model {} from {}'.format(model.modelName, pretrained_path))\n",
    "model.load_state_dict(torch.load(pretrained_path + '/model.rar', map_location=device))\n",
    "model._pz_params = model._pz_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescue = '../experiments/test/2020-04-28T17:13:31.932565bjdxippz'\n",
    "print('Loading model {} from {}'.format(model.modelName, rescue))\n",
    "model.load_state_dict(torch.load(rescue + '/model.rar.old', map_location=device))\n",
    "model._pz_params = model._pz_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit = False\n",
    "model.init_gmm_params(train_loader, fit=fit, var=0.1, device=device)\n",
    "#model.init_gmm_params_separate(train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pi= model._pz_params[0].detach()\n",
    "pre_mu = model._pz_params[1].detach()\n",
    "pre_var = model._pz_params[2].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pre_pi)\n",
    "print(pre_mu)\n",
    "print(pre_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model._pz_params[0]/sum(model._pz_params[0]))\n",
    "print(model._pz_params[1])\n",
    "print(model._pz_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                       lr=1e-4, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objective = getattr(objectives, 'elbo_vade') \n",
    "objective = getattr(objectives, 'm_elbo_naive_vade') \n",
    "#objective = getattr(objectives, 'm_elbo_vade') \n",
    "#objective = getattr(objectives, 'm_elbo_vade_warmup') \n",
    "#objective = getattr(objectives, 'm_elbo_vade_separate') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, agg, W=30):\n",
    "    model.train()\n",
    "    b_loss = 0\n",
    "    adj = 1\n",
    "    #beta = (epoch - 1) / W  if epoch <= W else 1\n",
    "    \n",
    "    alpha = 100\n",
    "    beta = alpha * (epoch - 1) / W if epoch<=W else alpha\n",
    "    for i, dataT in enumerate(train_loader):\n",
    "        \n",
    "        #data = unpack_data(dataT, device=device) #unimodal\n",
    "        data = dataT #multimodal\n",
    "        optimizer.zero_grad()\n",
    "        if objective==getattr(objectives, 'm_elbo_vade_warmup'):\n",
    "            loss = -objective(model, data, beta, K=args.K)\n",
    "        else:\n",
    "            loss = -objective(model, data, adj=adj, K=args.K)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        b_loss += loss.item()\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "b_loss = 0\n",
    "adj = 1\n",
    "#beta = (epoch - 1) / W  if epoch <= W else 1\n",
    "\n",
    "alpha = 100\n",
    "#beta = alpha * (epoch - 1) / W if epoch<=W else alpha\n",
    "for i, dataT in enumerate(train_loader):\n",
    "    \n",
    "    #data = unpack_data(dataT, device=device) #unimodal\n",
    "    data = dataT #multimodal\n",
    "    optimizer.zero_grad()\n",
    "    if objective==getattr(objectives, 'm_elbo_vade_warmup'):\n",
    "        loss = -objective(model, data, beta, K=args.K)\n",
    "    else:\n",
    "        loss = -objective(model, data, adj=adj, K=args.K)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    b_loss += loss.item()\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/arch.png.pdf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Source\n",
    "from torchviz import make_dot\n",
    "arch = make_dot(loss)\n",
    "Source(arch).render('../data/arch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Timer('MM-VAE') as t:\n",
    "        agg = defaultdict(list)\n",
    "        # initialize the early_stopping object\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=True) \n",
    "        \n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            train(epoch, agg)\n",
    "            #save_model(model, runPath + '/model.rar')\n",
    "            save_vars(agg, runPath + '/losses.rar')\n",
    "            \n",
    "            # early_stopping needs the validation loss to check if it has decresed, \n",
    "            # and if it has, it will make a checkpoint of the current model\n",
    "            #validate(epoch, agg)\n",
    "            #early_stopping(agg['val_loss'][-1], model, runPath)\n",
    "            early_stopping(agg['train_loss'][-1], model, runPath)\n",
    "            if early_stopping.early_stop:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "            \n",
    "            #test(epoch, agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MMVAE get all data\n",
    "for i, d in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        data0 = d[0]\n",
    "        data1 = d[1]\n",
    "    else:\n",
    "        data0 = torch.cat([data0, d[0]], dim=0)\n",
    "        data1 = torch.cat([data1, d[1]], dim=0)\n",
    "data = [data0.to(device), data1.to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize_latent(data, runPath, epoch=1, tsne=True, sampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMVAE get n data\n",
    "n = 1\n",
    "for i, d in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        data0 = d[0]\n",
    "        data1 = d[1]\n",
    "    elif i < n:\n",
    "        data0 = torch.cat([data0, d[0]], dim=0)\n",
    "        data1 = torch.cat([data1, d[1]], dim=0)\n",
    "data = [data0.to(device), data1.to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing m_elbo_naive_vade\n",
    "x = data\n",
    "qz_xs, px_zs, zss = model(x)\n",
    "n_centroids = model.params.n_centroids\n",
    "lpx_zs, klds = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vaes[0]._qz_x_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, qz_x in enumerate(qz_xs):\n",
    "    zs = zss[r]\n",
    "    kld = vade_kld(model, zs, r)\n",
    "    klds.append(kld)\n",
    "        \n",
    "    for d, px_z in enumerate(px_zs[r]):\n",
    "        lpx_z = px_z.log_prob(x[d]) * model.vaes[d].llik_scaling\n",
    "        #lpx_zs.append(lpx_z.view(*px_z.batch_shape[:2], -1).sum(-1).squeeze()) #added squeeze()\n",
    "        lpx_zs.append(lpx_z.sum(-1))\n",
    "#obj = (1 / len(model.vaes)) * (torch.stack(lpx_zs).sum(0) - torch.stack(klds).sum(0))\n",
    "obj = (1 / len(model.vaes)) * (torch.stack(lpx_zs).sum(0) - torch.stack(klds).sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(lpx_zs).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "klds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0\n",
    "zs = zss[r]\n",
    "n_centroids = model.params.n_centroids\n",
    "gamma, lgamma, mu_c, var_c, pi = model.get_gamma(zs)\n",
    "    \n",
    "    #mu, logvar = model.vaes[r]._qz_x_params ミス \n",
    "mu, var = model.vaes[r]._qz_x_params\n",
    "mu_expand = mu.unsqueeze(2).expand(mu.size(0), mu.size(1), n_centroids)\n",
    "    #logvar_expand = logvar.unsqueeze(2).expand(logvar.size(0), logvar.size(1), n_centroids)\n",
    "var_expand = var.unsqueeze(2).expand(var.size(0), var.size(1), n_centroids)\n",
    "        \n",
    "    #lpz_c = -0.5*torch.sum(gamma*torch.sum(math.log(2*math.pi) + \\\n",
    "    #                                       torch.log(var_c) + \\\n",
    "    #                                       torch.exp(logvar_expand)/var_c + \\\n",
    "    #                                       (mu_expand-mu_c)**2/var_c, dim=1), dim=1) # log p(z|c)\n",
    "lpz_c = -0.5*torch.sum(gamma*torch.sum(math.log(2*math.pi) + \\\n",
    "                                           torch.log(var_c) + \\\n",
    "                                           var_expand/var_c + \\\n",
    "                                           (mu_expand-mu_c)**2/var_c, dim=1), dim=1) # log p(z|c)\n",
    "lpc = torch.sum(gamma*torch.log(pi), 1) # log p(c)\n",
    "lqz_x = -0.5*torch.sum(1+torch.log(var)+math.log(2*math.pi), 1) #see VaDE paper # log q(z|x)\n",
    "lqc_x = torch.sum(gamma*(lgamma), 1) # log q(c|x)\n",
    "    \n",
    "kld = -lpz_c - lpc + lqz_x + lqc_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpz_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lqz_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " -lpz_c - lpc + lqz_x + lqc_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_multimodal2",
   "language": "python",
   "name": "venv_multimodal2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
