{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 最尤推定と線形モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 確率モデルと最尤推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率モデルとは次のように変数 $x$ がパラメータ $\\theta$ をもつある確率分布 $P(x|\\theta)$ から生成されていると仮定しているモデルを指します。\n",
    "$$x \\sim P(x|\\theta) $$\n",
    "\n",
    "ある互いに独立な $N$ 個のデータ $X = (x_{0}, x_{1}, \\cdots)$ が与えられたとき、以下のように各データの確率関数の値の積を $\\theta$ の関数とすると、これは $\\theta$ の尤もらしさとなり、尤度（Likelihood）と呼ばれます。\n",
    "$$L(\\theta) = \\prod_{n} P(x_{n}|\\theta)$$\n",
    "\n",
    "尤度は確率モデルで最も重要な量であり、尤度を最大にするようなパラメータ $\\theta$ を求めることを最尤推定（Maximum Likelihood Estimation, MLE）といいます。\n",
    "\n",
    "通常は計算のしやすさなどから対数尤度の形で扱われます。\n",
    "$$\\mbox{ln}L(\\theta) = \\sum_{n}\\mbox{ln}P(x_{n}|\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 確率的勾配降下法\n",
    "対数尤度関数の微分が 0 になる方程式に解析解が無い場合には、数値的に最適化をしていきます。また、この分野では一般的にある目的関数を最小化することを目的とします。このように最小化する場合の目的関数は損失関数（Loss Function）とも呼ばれます。そのため、対数尤度関数を最大化するのではなく、符号を反転したものを最小化することが目的となります。\n",
    "$$\\theta_{MLE} = \\mathop{\\rm arg~min}\\limits_{\\theta} E(\\theta)$$\n",
    "$$E(\\theta) = -\\mbox{ln}L(\\theta)$$\n",
    "\n",
    "こういった微分可能な関数の数値最適化を解く最もシンプルな方法は勾配降下法（Gradient Descent）と呼ばれるもので、以下のように勾配（微分係数）を利用して繰り返し最適化していく方法です。\n",
    "$$\\theta^{t+1} = \\theta^{t} - \\gamma\\frac{\\partial}{\\partial \\theta}E(\\theta^{t})$$\n",
    "\n",
    "ここで $\\gamma$ は学習率パラメータで正の値です。学習率が大きいと損失関数の減少も速いですが、うまく収束せずに振動してしまう可能性があります。\n",
    "\n",
    "一方、学習率が小さいと損失関数の減少が遅く、収束するまでに何回も計算が必要になります。特に対数尤度関数のように目的関数が同じ形の関数の和に分解できる時にはすべての値を使用するのではなく、ランダムに一部の値（ミニバッチ）のみを使用する確率的勾配降下（Stochastic Gradient Descent, SGD）やその亜種が利用でき、ビッグデータなどデータが多い場合に非常に効果的であることが知られています。\n",
    "$$E(\\theta) = \\sum_{n}E_{n}(\\theta)$$\n",
    "$$\\theta^{t+1} = \\theta^{t} - \\gamma \\sum_{n\\in batch} E_{n}(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 線形回帰モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 線形回帰モデルの最尤推定\n",
    "線形回帰モデル（Linear Regression）モデルは複数の変数から 1 つ、または複数の値を予測するための手法です。次のような式で表されます。\n",
    "$$y = \\boldsymbol{a} \\cdot \\boldsymbol{x} + b + \\epsilon = \\sum_{i}a_{i}x_{i} + b + \\epsilon$$\n",
    "\n",
    "ここで $\\boldsymbol{x}$ は独立変数や特徴量といい、$y$ は予測したい目的変数、$\\boldsymbol{a}, b$ がモデルのパラメータ（回帰係数）、$\\epsilon$ は正規分布 $\\mathcal{N}(0, \\sigma^{2})$ に従う誤差項です。$x$ から $y$ を予測することが目的です。変数 $x$ に 1 も含めて、$(1, x_{1}, x_{2}, \\cdots)$ のように表すことで、切片項 $b$ も回帰係数 $\\boldsymbol{a}$ に含めることができ、次のような簡潔な式になります。\n",
    "$$y = \\boldsymbol{a}\\cdot\\boldsymbol{x}$$\n",
    "\n",
    "一方、線形回帰モデルは確率モデルでもあり、次のようにも表せます。\n",
    "$$y \\sim \\mathcal{N}(x|\\boldsymbol{a} \\cdot \\boldsymbol{x}, \\sigma^{2})$$\n",
    "\n",
    "$N$ 個のデータが与えられたとき、線形回帰モデルの対数尤度関数は以下のようになります。\n",
    "$$\\mbox{ln}L(\\boldsymbol{a}) = -\\frac{N}{2}\\mbox{ln}2\\pi\\sigma^{2} - \\frac{1}{2\\sigma^{2}}\\sum_{n}(y_{n}-m_{n})^{2}$$\n",
    "$$m_{n} = \\sum_{i}a_{i}x_{ni}$$\n",
    "\n",
    "$\\boldsymbol{a}$ で微分を作る時に意味がある項だけ残すと、実際には次のように平均二乗誤差（Mean Squared Error, MSE）を最小化するという問題になります。\n",
    "$$E(\\boldsymbol{a}) = \\sum_{i}E_{n}(\\boldsymbol{a}) = \\frac{1}{N}\\sum_{n}(y_{n} - \\boldsymbol{a}_{n} \\cdot \\boldsymbol{x}_{n})^{2}$$\n",
    "\n",
    "この $E(\\boldsymbol{a})$ を最小化させることで、モデルの $\\boldsymbol{a}$ を最尤推定することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 PyTorch で線形回帰モデル（from scratch）\n",
    "ここでは次のような 2 変数のモデルを考える\n",
    "$$y = 1 + 2x_{1} + 3x_{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータを生成してパラメータを学習するための変数を準備\n",
    "import torch\n",
    "\n",
    "# 真の係数\n",
    "w_true = torch.Tensor([1, 2, 3])\n",
    "\n",
    "# X のデータの準備。切片を回帰係数に含めるため、X の最初の次元に 1 を追加しておく\n",
    "X = torch.cat([torch.ones(100, 1), torch.randn(100, 2)], 1)\n",
    "\n",
    "# 真の係数と各 X との内積を行列とベクトルの積でまとめて計算\n",
    "y = torch.mv(X, w_true) + torch.randn(100) * 0.5\n",
    "\n",
    "# 勾配降下で最適化するためのパラメータの Tensor を乱数で初期化して作成\n",
    "w = torch.randn(3, requires_grad=True)\n",
    "\n",
    "# 学習率\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor(list)` : list の値の Tensor を作成  \n",
    "`torch.randn(n, m)` : n × m 行のテンソルを正規分布乱数で作る  \n",
    "`torch.cat(Tensor1, Tensor2, dim)` : dim のところで Tensor1, Tensor2 を結合する  \n",
    "`torch.ones(size)` : 指定したサイズの 1 配列を作る  \n",
    "`torch.mv()` : 2 次元 × 1 次元の計算を行う  \n",
    "`requires_grad = True` : 微分可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配降下法でパラメータを最適化\n",
    "\n",
    "# 損失関数のログ\n",
    "losses = []\n",
    "\n",
    "# 100 回イテレーションを回す\n",
    "for epoc in range(100):\n",
    "    # 前回の backward メソッドで計算された勾配の値を削除\n",
    "    w.grad = None\n",
    "    \n",
    "    # 線形モデルで y の予測値を計算\n",
    "    y_pred = torch.mv(X, w)\n",
    "    \n",
    "    # MSE loss と w による微分を計算\n",
    "    loss = torch.mean((y-y_pred)**2)\n",
    "    loss.backward()\n",
    "    \n",
    "    # 勾配を更新する。w をそのまま代入して更新すると異なる Tensor になって計算グラフが破壊されてしまうので data だけ更新する\n",
    "    w.data = w.data - gamma*w.grad.data\n",
    "    \n",
    "    # 収束確認のために loss を記録しておく\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.mean(X)` : X の平均値を計算  \n",
    "`X.backward()` : X の微分計算  \n",
    "`Tensor.item()` : Tensor の値だけを取り出す（`requires_grad=True` の場合に用いる？）  \n",
    "`x.grad` : x の勾配情報  \n",
    "`x.data` : x の中身を取り出す（`requires_grad=False` の Tensor のみに使える？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f452c4bbcf8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib でプロット\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0754, 2.0091, 3.0313], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 回帰係数の確認\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Pytorch 線形回帰モデル（nn, optim モジュールの使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形回帰モデルの構築と最適化の準備\n",
    "from torch import nn, optim\n",
    "\n",
    "# Linear 層を作成。今回は切片項は回帰係数に含めるので、入力の次元を 3 とし、bias（切片）を False にする\n",
    "net = nn.Linear(in_features=3, out_features=1, bias=False)\n",
    "\n",
    "# SGD のオプティマイザーに上で定義したネットワークのパラメータを渡して初期化\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# MSE loss クラス\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(in, out)` : 入力に重みとバイアスによる線形変換を行う（今回はバイアスを用いない）  \n",
    "`optim.SGD` : SGD の計算を行う関数。`lr` は学習率  \n",
    "詳細：https://qiita.com/mathlive/items/2c67efa2d451ea1da1b1  \n",
    "`network.parameters()` : network のパラメータを渡す（ここでは微分可能である必要がある）  \n",
    "`nn.MSELoss()` : 平均二乗誤差を計算するモジュールで、損失関数として用いている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化のイテレーション（繰り返しループ）を回す\n",
    "\n",
    "# 損失関数のログ\n",
    "losses = []\n",
    "\n",
    "# 100 回イテレーションを回す\n",
    "for epoc in range(100):\n",
    "    # 前回の backward メソッドで計算された勾配の値を削除\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 線形回帰モデルで y の予測値を計算\n",
    "    y_pred = net(X)\n",
    "    \n",
    "    # MSE loss を計算。y_pred は (n, 1) のような shape を持っているので (n, )に直す必要がある\n",
    "    loss = loss_fn(y_pred.view_as(y), y)\n",
    "    \n",
    "    # loss の w による微分を計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # 勾配を更新する\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 収束確認のために loss を記録しておく\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optimizer.zero_grad()` : 勾配の値を削除する関数。これを行わないと前に計算した勾配が残り、最小化する方向に勾配が向かない  \n",
    "`x.view_as(y)` : x を y と同じサイズに変換する  \n",
    "`x.step()` : x のパラメータを更新する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.0754, 2.0091, 3.0313]], requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 収束したモデルのパラメータを確認\n",
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 ロジスティック回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 ロジスティック回帰の最尤推定\n",
    "\n",
    "ロジスティック回帰は名前に回帰とついていますが、実は分類のための線形モデルです。線形回帰は目的変数 y が連続値でしたが、ロジスティック回帰では y は $[0, 1]$ の離散値で、2 クラスの分類問題になります。\n",
    "\n",
    "変数の線形結合はそのままでは $[-\\infty , \\infty]$ までの間で任意の値をとれてしまうため、ロジスティック回帰では線形結合を取った後に、さらにシグモイド関数 $\\sigma(x)$ を作用させて $[0, 1]$ の間の値に変換します。\n",
    "\n",
    "$$h = \\boldsymbol{a} \\cdot \\boldsymbol{x} , z = \\sigma(h) = \\frac{1}{1 + e^{-h}}$$\n",
    "\n",
    "線形回帰モデルと同様、ロジスティック回帰も確率モデルです。このモデルでは $y$ がパラメータ $z$ のベルヌーイ分布に従うと仮定します $(y\\sim B(z))$。そのため、最尤推定に使うための損失関数は 2.1 節で登場したベルヌーイ分布の尤度の式と比べると次のようにクロスエントロピー（Cross Entropy）と呼ばれる量になります。\n",
    "\n",
    "$$E(\\boldsymbol{a}) = -\\sum_{n}y_{n}\\mbox{ln}z_{n} + (1-y_{n})\\mbox{ln}(1-z_{n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 PyTorch でロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris のデータセットの準備\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# iris は (0, 1, 2) の 3 クラスの分類問題なのでここでは (0, 1) の 2 クラス文のデータだけを使用する\n",
    "# 本来は訓練用とテスト用にデータを分けるべきだがここでは省略\n",
    "X = iris.data[:100]\n",
    "y = iris.target[:100]\n",
    "\n",
    "# Numpy の ndarray を PyTorch の Tensor に変換\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの作成\n",
    "\n",
    "# iris のデータは 4 次元\n",
    "net = nn.Linear(4, 1)\n",
    "\n",
    "# シグモイド関数を作用させ、2 クラス分類の、クロスエントロピーを計算する関数\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# SGD（少し大きめの学習率）\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.BCEWithLogitsLoss()` : シグモイド関数を用いたバイナリクロスエントロピーの計算を行う。  \n",
    "参考：http://37ma5ras.blogspot.com/2017/12/loss-function.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ最適化のイテレーションを回す\n",
    "\n",
    "# 損失関数のログ\n",
    "losses = []\n",
    "\n",
    "# 100 回イテレーションを回す\n",
    "for epoc in range(100):\n",
    "    # 前回の backward メソッドで計算された勾配の値を削除\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 線形モデルで y の予測値を計算\n",
    "    y_pred = net(X)\n",
    "    \n",
    "    # MSE loss と w による微分を計算\n",
    "    loss = loss_fn(y_pred.view_as(y), y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # 勾配を更新する\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 収束確認のために loss を記録しておく\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4525db0940>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの作成\n",
    "\n",
    "# 線形結合の結果\n",
    "h = net(X)\n",
    "\n",
    "# シグモイド関数を作用させた結果は y=1 の確率を表す\n",
    "prob = nn.functional.sigmoid(h)\n",
    "\n",
    "# 確率が 0.5 以上のものを クラス 1 と予想し、それ以外を 0 とする\n",
    "# PyTorch には Bool 型がないので、対応する型として ByteTensor が出力される\n",
    "y_pred = prob > 0.5\n",
    "\n",
    "# 予測結果の確認（y はFloatTensor なので、ByteTensor に変換してから比較する）\n",
    "\n",
    "(y.byte() == y_pred.view_as(y)).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.functional.sigmoid(x)` : x をシグモイド関数に作用させる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 多クラスのロジスティック回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰は 2 クラスだけでなく、多クラスの分類問題にも拡張できます。行うこととしては、線形結合層の出力を 1 次元でなくクラス数分の次元にし、損失関数をソフトマックスクロスエントロピーというクロスエントロピー関数の多クラス版で置き換えるだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 種類の手書きの数字のデータセットの分類問題\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# CrossEntropyLoss 関数は y として int64 型の Tensor を受け取るので注意\n",
    "y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "# 出力は 10（クラス数）次元\n",
    "net = nn.Linear(X.size()[1], 10)\n",
    "\n",
    "# ソフトマックスクロスエントロピー\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.CrossEntropyLoss()` : クロスエントロピーを損失関数として用いる  \n",
    "参考：https://qiita.com/Haaamaaaaa/items/58ba0962a8fcd1eeb82e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習のイテレーション部分\n",
    "\n",
    "# 損失関数のログ\n",
    "losses = []\n",
    "\n",
    "# 100 回イテレーションを回す\n",
    "for epoc in range(100):\n",
    "    # 前回の backward メソッドで計算された勾配の値を削除\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 線形モデルで y の予測値を計算\n",
    "    y_pred = net(X)\n",
    "    \n",
    "    # MSE loss と w による微分を計算\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # 勾配を更新する\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 収束確認のために loss を記録しておく\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393433500278241"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解率\n",
    "\n",
    "# torch.max は集計軸を指定すると最大値のほかにその位置も返す\n",
    "_, y_pred = torch.max(net(X), 1)\n",
    "\n",
    "# 正解軸を計算する\n",
    "(y_pred == y).sum().item() / len(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
