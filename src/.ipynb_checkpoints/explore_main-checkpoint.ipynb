{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse\n",
    "import datetime\n",
    "import sys\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "from torch import optim\n",
    "\n",
    "import math\n",
    "\n",
    "import models\n",
    "#import objectives\n",
    "import objectives_dev as objectives\n",
    "from utils import Logger, Timer, save_model, save_vars, unpack_data\n",
    "\n",
    "from utils import log_mean_exp, is_multidata, kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#args\n",
    "experiment = 'atac'\n",
    "model = 'atac_dev' #VAE試しに使う\n",
    "obj = 'dreg'\n",
    "K = 20\n",
    "looser = False\n",
    "llik_scaling = 0\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "latent_dim = 20\n",
    "num_hidden_layers = 1\n",
    "learn_prior = False\n",
    "logp = False\n",
    "print_freq = 0\n",
    "no_analytics = True\n",
    "seed = 1\n",
    "\n",
    "class params():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 experiment,\n",
    "                 model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed):\n",
    "        \n",
    "        self.experiment = experiment\n",
    "        self.model = model\n",
    "        self.obj = obj\n",
    "        self.K = K\n",
    "        self.looser = looser\n",
    "        self.llik_scaling = llik_scaling\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.learn_prior = learn_prior\n",
    "        self.logp = logp\n",
    "        self.print_freq = print_freq\n",
    "        self.no_analytics = no_analytics\n",
    "        self.seed = seed\n",
    "        \n",
    "args = params(experiment,\n",
    "                model,\n",
    "                 obj,\n",
    "                 K,\n",
    "                 looser,\n",
    "                 llik_scaling,\n",
    "                 batch_size,\n",
    "                 epochs,\n",
    "                 latent_dim,\n",
    "                 num_hidden_layers,\n",
    "                 learn_prior,\n",
    "                 logp,\n",
    "                 print_freq,\n",
    "                 no_analytics,\n",
    "                 seed)\n",
    "\n",
    "# random seed\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# load model\n",
    "modelC = getattr(models, 'VAE_{}'.format(args.model))\n",
    "model = modelC(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNIST' object has no attribute 'vaes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-2e0be6789b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/multimodal/venv_multimodal/lib/python3.7/site-packages/torch-1.3.1-py3.7-macosx-10.9-x86_64.egg/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'vaes'"
     ]
    }
   ],
   "source": [
    "print(model.vaes[0])\n",
    "print('')\n",
    "print(model.vaes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  data ...\n",
      "Original data contains 5081 cells x 229429 peaks\n",
      "Finished loading takes 0.35 min\n"
     ]
    }
   ],
   "source": [
    "# preparation for training\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                       lr=1e-3, amsgrad=True)\n",
    "train_loader, test_loader = model.getDataLoaders(args.batch_size, device=device)\n",
    "objective = getattr(objectives,\n",
    "                    ('m_' if hasattr(model, 'vaes') else '')\n",
    "                    + args.obj\n",
    "                    + ('_looser' if (args.looser and args.obj != 'elbo') else ''))\n",
    "t_objective = getattr(objectives, ('m_' if hasattr(model, 'vaes') else '') + 'iwae')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, agg):\n",
    "    model.train()\n",
    "    b_loss = 0\n",
    "    for i, dataT in enumerate(train_loader):\n",
    "        data = unpack_data(dataT, device=device) #RNA_ATAC MMVAEでこの変換いらない\n",
    "        optimizer.zero_grad()\n",
    "        loss = -objective(model, data, K=args.K)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        b_loss += loss.item()\n",
    "        if args.print_freq > 0 and i % args.print_freq == 0:\n",
    "            print(\"iteration {:04d}: loss: {:6.3f}\".format(i, loss.item() / args.batch_size))\n",
    "    agg['train_loss'].append(b_loss / len(train_loader.dataset))\n",
    "    print('====> Epoch: {:03d} Train loss: {:.4f}'.format(epoch, agg['train_loss'][-1]))\n",
    "    \n",
    "    \n",
    "def test(epoch, agg):\n",
    "    model.eval()\n",
    "    b_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, dataT in enumerate(test_loader):\n",
    "            data = unpack_data(dataT, device=device) #RNA_ATAC MMVAEでこの変換いらない\n",
    "            #loss = -t_objective(model, data, K=args.K) \n",
    "            loss = -objective(model, data, K=args.K) #t_objectiveの意味がよくわからないので、trainと同じobjectivesにした\n",
    "            b_loss += loss.item()\n",
    "#            if i == 0:\n",
    "#               model.reconstruct(data, runPath, epoch)\n",
    "#                if not args.no_analytics:\n",
    "#                    model.analyse(data, runPath, epoch)\n",
    "    agg['test_loss'].append(b_loss / len(test_loader.dataset))\n",
    "    print('====>             Test loss: {:.4f}'.format(agg['test_loss'][-1]))\n",
    "\n",
    "    \n",
    "def estimate_log_marginal(K):\n",
    "    \"\"\"Compute an IWAE estimate of the log-marginal likelihood of test data.\"\"\"\n",
    "    model.eval()\n",
    "    marginal_loglik = 0\n",
    "    with torch.no_grad():\n",
    "        for dataT in test_loader:\n",
    "            data = unpack_data(dataT, device=device)\n",
    "            marginal_loglik += -t_objective(model, data, K).item()\n",
    "\n",
    "    marginal_loglik /= len(test_loader.dataset)\n",
    "    print('Marginal Log Likelihood (IWAE, K = {}): {:.4f}'.format(K, marginal_loglik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "b_loss = 0\n",
    "\n",
    "#1epoch のみ run\n",
    "for i, dataT in enumerate(train_loader):\n",
    "    data = unpack_data(dataT, device=device)\n",
    "#    optimizer.zero_grad()\n",
    "#    loss = -objective(model, data, K=args.K)\n",
    "#    loss.backward()\n",
    "#    optimizer.step()\n",
    "#    b_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([6, 0, 4, 8, 6, 3, 3, 3, 1, 2, 3, 4, 6, 4, 0, 1, 8, 5, 0, 7, 8, 3, 5, 3,\n",
      "        4, 1, 6, 2, 8, 5, 9, 4, 2, 2, 2, 7, 6, 9, 7, 6, 4, 6, 8, 9, 3, 7, 6, 0,\n",
      "        0, 1, 4, 9, 5, 8, 1, 3, 6, 2, 9, 3, 1, 2, 6, 3, 5, 0, 9, 1, 3, 7, 9, 0,\n",
      "        1, 5, 6, 5, 4, 1, 7, 3, 8, 4, 1, 4, 8, 7, 8, 4, 6, 1, 4, 2, 1, 4, 8, 2])]\n",
      "\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = unpack_data(dataT,device='cpu')\n",
    "print(dataT)\n",
    "print('')\n",
    "print(data)\n",
    "type(dataT)\n",
    "print(is_multidata(dataT))\n",
    "torch.is_tensor(dataT[0])\n",
    "\n",
    "#data = [d.to(device) for d in list(zip(*dataT))[0]]\n",
    "#len(data[0])\n",
    "#len(data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_elbo(model, x, K=1):\n",
    "    \"\"\"Computes importance-sampled m_elbo (in notes3) for multi-modal vae \"\"\"\n",
    "    qz_xs, px_zs, zss = model(x)\n",
    "    lpx_zs, klds = [], []\n",
    "    for r, qz_x in enumerate(qz_xs):\n",
    "        kld = kl_divergence(qz_x, model.pz(*model.pz_params))\n",
    "        klds.append(kld.sum(-1))\n",
    "        for d in range(len(px_zs)):\n",
    "            lpx_z = px_zs[d][d].log_prob(x[d]).view(*px_zs[d][d].batch_shape[:2], -1)\n",
    "            lpx_z = (lpx_z * model.vaes[d].llik_scaling).sum(-1)\n",
    "            if d == r:\n",
    "                lwt = torch.tensor(0.0)\n",
    "            else:\n",
    "                zs = zss[d].detach()\n",
    "                lwt = (qz_x.log_prob(zs) - qz_xs[d].log_prob(zs).detach()).sum(-1)\n",
    "            lpx_zs.append(lwt.exp() * lpx_z)\n",
    "    obj = (1 / len(model.vaes)) * (torch.stack(lpx_zs).sum(0) - torch.stack(klds).sum(0))\n",
    "    return obj.mean(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-16452406., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "obj = m_elbo(model,dataT,K=1)\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataT in enumerate(train_loader):\n",
    "    data = unpack_data(dataT, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([217, 19322])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c9b145e32589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(loss)\n",
    "print(optimizer)\n",
    "print(b_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "b_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, dataT in enumerate(test_loader):\n",
    "        data = unpack_data(dataT, device=device)\n",
    "        #loss = -t_objective(model, data, K=args.K)\n",
    "        loss = -objective(model, data, K=args.K) #t_objectiveの意味がよくわからないので、trainと同じobjectivesにした\n",
    "        b_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up run path\n",
    "runId = datetime.datetime.now().isoformat()\n",
    "experiment_dir = Path('../experiments/' + args.experiment)\n",
    "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "runPath = mkdtemp(prefix=runId, dir=str(experiment_dir))\n",
    "#sys.stdout = Logger('{}/run.log'.format(runPath))\n",
    "#print('Expt:', runPath)\n",
    "#print('RunID:', runId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 001 Train loss: -109.2966\n",
      "====>             Test loss: -223.3064\n",
      "====> Epoch: 002 Train loss: -268.7529\n",
      "====>             Test loss: -309.7857\n",
      "====> Epoch: 003 Train loss: -322.1698\n",
      "====>             Test loss: -345.1194\n",
      "====> Epoch: 004 Train loss: -345.4030\n",
      "====>             Test loss: -361.0003\n",
      "====> Epoch: 005 Train loss: -361.6680\n",
      "====>             Test loss: -375.9831\n",
      "====> Epoch: 006 Train loss: -371.7375\n",
      "====>             Test loss: -382.8655\n",
      "====> Epoch: 007 Train loss: -378.1016\n",
      "====>             Test loss: -389.0620\n",
      "====> Epoch: 008 Train loss: -384.4498\n",
      "====>             Test loss: -395.1035\n",
      "====> Epoch: 009 Train loss: -390.3915\n",
      "====>             Test loss: -401.5373\n",
      "====> Epoch: 010 Train loss: -394.1692\n",
      "====>             Test loss: -404.0607\n",
      "====> [MM-VAE] Time:  85.220s or 00:01:25\n"
     ]
    }
   ],
   "source": [
    "with Timer('MM-VAE') as t:\n",
    "        agg = defaultdict(list)\n",
    "        \n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            train(epoch, agg)\n",
    "            test(epoch, agg)\n",
    "#            save_model(model, runPath + '/model.rar')\n",
    "#            save_vars(agg, runPath + '/losses.rar')\n",
    "#            model.generate(runPath, epoch)\n",
    "#        if args.logp:  # compute as tight a marginal likelihood as possible\n",
    "#            estimate_log_marginal(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, runPath + '/model.rar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class VAE のforward\n",
    "model._qz_x_params = model.enc(dataT) #Encoderを通して確率分布のパラメータを渡す\n",
    "qz_x = model.qz_x(*model._qz_x_params) #qz_x はLaplace分布\n",
    "print(qz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zs = qz_x.rsample(torch.Size([10])) #各サンプルについてqz_xからzをサンプリング\n",
    "print(zs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = model.dec(zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(recon))\n",
    "#print(recon.shape)\n",
    "print(len(recon))\n",
    "print(recon[0].shape)\n",
    "print(recon[1].shape)\n",
    "print(recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_z = model.px_z(*model.dec(zs)) #likelihood\n",
    "print(px_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objectives of choice\n",
    "import torch\n",
    "from numpy import prod\n",
    "\n",
    "from utils import log_mean_exp, is_multidata, kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model(x)) #forwardは　qz_x, px_z, zs　を返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = dataT\n",
    "qz_x, px_z, _ = model(x)\n",
    "lpx_z = px_z.log_prob(x).view(*px_z.batch_shape[:2], -1) * model.llik_scaling \n",
    "#lpx_z = px_z.log_prob(x).view(*px_z.batch_shape[:1], -1) * model.llik_scaling \n",
    "kld = kl_divergence(qz_x, model.pz(*model.pz_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataT.shape)\n",
    "print(px_z.log_prob(x).shape)\n",
    "print(*px_z.batch_shape[:2])\n",
    "print(px_z.log_prob(x).view(*px_z.batch_shape[:2], -1).shape)\n",
    "print(px_z.batch_shape)\n",
    "print(lpx_z.shape)\n",
    "print(kld.shape)\n",
    "print(kld.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class MMVAE forward\n",
    "def forward(self, x, K=1):\n",
    "    qz_xs, zss = [], []\n",
    "    # initialise cross-modal matrix\n",
    "    px_zs = [[None for _ in range(len(self.vaes))] for _ in range(len(self.vaes))]\n",
    "    for m, vae in enumerate(self.vaes):\n",
    "        qz_x, px_z, zs = vae(x[m], K=K)\n",
    "        qz_xs.append(qz_x)\n",
    "        zss.append(zs)\n",
    "        px_zs[m][m] = px_z  # fill-in diagonal\n",
    "    for e, zs in enumerate(zss):\n",
    "        for d, vae in enumerate(self.vaes):\n",
    "            if e != d:  # fill-in off-diagonal\n",
    "                px_zs[e][d] = vae.px_z(*vae.dec(zs))\n",
    "    return qz_xs, px_zs, zss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qz_xs, zss = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise cross-modal matrix\n",
    "px_zs = [[None for _ in range(len(model.vaes))] for _ in range(len(model.vaes))]\n",
    "print(px_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataT\n",
    "for m, vae in enumerate(model.vaes):\n",
    "        qz_x, px_z, zs = vae(x[m], K=K)\n",
    "        qz_xs.append(qz_x)\n",
    "        zss.append(zs)\n",
    "        px_zs[m][m] = px_z  # fill-in diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qz_x)\n",
    "print(qz_xs)\n",
    "print('')\n",
    "print(px_z)\n",
    "print(px_zs) #Cross-modal matrix\n",
    "print('')\n",
    "print(zs.shape)\n",
    "print(len(zss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for e, zs in enumerate(zss):\n",
    "        for d, vae in enumerate(model.vaes):\n",
    "            if e != d:  # fill-in off-diagonal\n",
    "                px_zs[e][d] = vae.px_z(*vae.dec(zs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(px_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_multimodal",
   "language": "python",
   "name": "venv_multimodal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
